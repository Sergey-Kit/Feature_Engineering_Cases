{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 490513 entries, 0 to 490512\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   PERIOD        490513 non-null  object \n",
      " 1   cl_id         490513 non-null  int64  \n",
      " 2   MCC           490513 non-null  int64  \n",
      " 3   channel_type  490513 non-null  object \n",
      " 4   currency      490513 non-null  int64  \n",
      " 5   TRDATETIME    490513 non-null  object \n",
      " 6   amount        490513 non-null  float64\n",
      " 7   trx_category  490513 non-null  object \n",
      " 8   target_flag   490513 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 33.7+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv('rosbank_train.csv')\n",
    "raw_df['channel_type'] = raw_df['channel_type'].fillna('type0')\n",
    "raw_df.drop(['target_sum'], axis=1,inplace=True)\n",
    "raw_df['target_flag'].value_counts()\n",
    "raw_df.info()\n",
    "cl_ids_test = np.random.choice(raw_df.cl_id.unique(), size=1000, replace=False)\n",
    "cl_ids_test_set = set(cl_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transactions in train dataset:  388459\n",
      "Total transactions in test dataset:  102054\n"
     ]
    }
   ],
   "source": [
    "# create transactions dataset for train\n",
    "transactions_train = raw_df[~raw_df.cl_id.isin(cl_ids_test)].copy()\n",
    "print(\"Total transactions in train dataset: \", len(transactions_train))\n",
    "# create transactions dataset for test\n",
    "transactions_test = raw_df[raw_df.cl_id.isin(cl_ids_test)].copy()\n",
    "print(\"Total transactions in test dataset: \", len(transactions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with currency rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 2)\n"
     ]
    }
   ],
   "source": [
    "codes = pd.read_csv('./codes-all.csv')\n",
    "codes = codes[['NumericCode','AlphabeticCode']]\n",
    "codes.columns = ['currency','AlphabeticCode']\n",
    "codes = codes.dropna().reset_index(drop=True)\n",
    "codes['currency'] = codes['currency'].astype('int')\n",
    "codes = codes.drop_duplicates(subset=['currency']).reset_index(drop=True)\n",
    "print(codes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train = pd.merge(transactions_train, codes, how='left', on = 'currency')\n",
    "transactions_test = pd.merge(transactions_test, codes, how='left', on = 'currency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = pd.read_csv('./curr.csv')\n",
    "curr['CLOSE'] = curr['CLOSE'] / curr['NOMINAL']\n",
    "curr = curr[['TICKER','DATE','CLOSE']]\n",
    "curr.columns = ['AlphabeticCode','time','CLOSE']\n",
    "curr['time'] = pd.to_datetime(curr['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction amount into neg/pos values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-88-823ca6a1d665>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transactions_train['amount'][ind] = abs(transactions_train['amount'][ind])\n",
      "<ipython-input-88-823ca6a1d665>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  transactions_test['amount'][ind] = abs(transactions_test['amount'][ind])\n"
     ]
    }
   ],
   "source": [
    "transactions_train['amount'] = -transactions_train['amount']\n",
    "ind = (transactions_train['trx_category']=='C2C_IN') | (transactions_train['trx_category']=='DEPOSIT') | (transactions_train['trx_category']=='BACK_TRX')\n",
    "transactions_train['amount'][ind] = abs(transactions_train['amount'][ind])\n",
    "\n",
    "transactions_test['amount'] = -transactions_test['amount']\n",
    "ind = (transactions_test['trx_category']=='C2C_IN') | (transactions_test['trx_category']=='DEPOSIT') | (transactions_test['trx_category']=='BACK_TRX')\n",
    "transactions_test['amount'][ind] = abs(transactions_test['amount'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cat_cols = ['channel_type','trx_category']\n",
    "for i in ['channel_type','trx_category']:\n",
    "    le = LabelEncoder()\n",
    "    le.fit( pd.concat([transactions_train[[i]], transactions_test[[i]]], axis=0) )\n",
    "    transactions_train[i] = le.transform(transactions_train[i])\n",
    "    transactions_test[i] = le.transform(transactions_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_dict = {\n",
    "    'JAN':'01',\n",
    "    'FEB':'02',\n",
    "    'MAR':'03',\n",
    "    'APR':'04',\n",
    "    'MAY':'05', \n",
    "    'JUN':'06',  \n",
    "    'JUL':'07',\n",
    "    'AUG':'08',\n",
    "    'SEP':'09',\n",
    "    'OCT':'10',\n",
    "    'NOV':'11', \n",
    "    'DEC':'12',   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_preprocess1(t):\n",
    "    day = t[0:2]\n",
    "    month = dt_dict[t[2:5]]\n",
    "    year = t[5:7]\n",
    "    \n",
    "    hour = t[8:10]\n",
    "    minute = t[11:13]\n",
    "    second = t[14:]\n",
    "    \n",
    "    return '20'+str(year)+'-'+str(month)+'-'+str(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train['time'] = transactions_train['TRDATETIME'].apply(lambda x: dt_preprocess1(x))\n",
    "transactions_train['time'] = pd.to_datetime(transactions_train['time'])\n",
    "transactions_test['time'] = transactions_test['TRDATETIME'].apply(lambda x: dt_preprocess1(x))\n",
    "transactions_test['time'] = pd.to_datetime(transactions_train['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_preprocess(t):\n",
    "    day = t[0:2]\n",
    "    month = dt_dict[t[2:5]]\n",
    "    year = t[5:7]\n",
    "    \n",
    "    hour = t[8:10]\n",
    "    minute = t[11:13]\n",
    "    second = t[14:]\n",
    "    \n",
    "    return '20'+str(year)+'-'+str(month)+'-'+str(day)+' '+str(hour)+\":\"+str(minute)+':'+str(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train['TRDATETIME'] = transactions_train['TRDATETIME'].apply(lambda x: dt_preprocess(x))\n",
    "transactions_train['TRDATETIME'] = pd.to_datetime(transactions_train['TRDATETIME'])\n",
    "transactions_test['TRDATETIME'] = transactions_test['TRDATETIME'].apply(lambda x: dt_preprocess(x))\n",
    "transactions_test['TRDATETIME'] = pd.to_datetime(transactions_test['TRDATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train['month'] = transactions_train['TRDATETIME'].dt.month + (transactions_train['TRDATETIME'].dt.year-2016)*12\n",
    "transactions_test['month'] = transactions_test['TRDATETIME'].dt.month + (transactions_test['TRDATETIME'].dt.year-2016)*12\n",
    "\n",
    "transactions_train['days_since2015'] = (transactions_train['TRDATETIME'] - pd.to_datetime('2015-01-01')).dt.days\n",
    "transactions_test['days_since2015'] = (transactions_test['TRDATETIME'] - pd.to_datetime('2015-01-01')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_test = pd.merge(transactions_test, curr, how='left', on=['AlphabeticCode','time'])\n",
    "transactions_train = pd.merge(transactions_train, curr, how='left', on=['AlphabeticCode','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_train['CLOSE'] = transactions_train['CLOSE'].fillna(1)\n",
    "transactions_train['amount'] = transactions_train['amount'] * transactions_train['CLOSE']\n",
    "transactions_train = transactions_train.drop(['currency', 'AlphabeticCode', 'CLOSE','time'], axis=1)\n",
    "transactions_test['CLOSE'] = transactions_test['CLOSE'].fillna(1)\n",
    "transactions_test['amount'] = transactions_test['amount'] * transactions_test['CLOSE']\n",
    "transactions_test = transactions_test.drop(['currency', 'AlphabeticCode', 'CLOSE','time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание DF по клиентам  + Фича времени в работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_monthes(x):\n",
    "    a = np.max(x) - np.min(x)\n",
    "    return a.days\n",
    "\n",
    "sum_deals = transactions_train[['cl_id','TRDATETIME']].groupby('cl_id').agg(diff_monthes).reset_index()\n",
    "sum_deals.columns = ['cl_id','num_days_in_use']\n",
    "df_train =  sum_deals\n",
    "\n",
    "sum_deals = transactions_test[['cl_id','TRDATETIME']].groupby('cl_id').agg(diff_monthes).reset_index()\n",
    "sum_deals.columns = ['cl_id','num_days_in_use']\n",
    "df_test =  sum_deals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разложение Weights of Evidence (WOE) фичи MCC кодов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_woe_v1(df_train, df_test, col, target_col):\n",
    "    all_good = len(df_train[df_train[target_col] == 1][col])\n",
    "    all_bad = len(df_train[df_train[target_col] == 0][col])\n",
    "    odds_series = (\n",
    "        df_train[df_train[target_col] == 1][col].value_counts()\n",
    "        /\n",
    "        df_train[df_train[target_col] == 0][col].value_counts()\n",
    "    )\n",
    "    odds_series = odds_series / all_good * all_bad\n",
    "    category_woe_dict = np.log(odds_series).to_dict()\n",
    "    df_train[col + '_woe'] = df_train[col].apply(category_woe_dict.get)\n",
    "    df_test[col + '_woe'] = df_test[col].apply(category_woe_dict.get)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_get_counts = [\n",
    "    'trx_category',\n",
    "    'MCC',\n",
    "    'channel_type'\n",
    "]\n",
    "    \n",
    "for col_get_prob in columns_to_get_counts:\n",
    "    transactions_train, transactions_test = get_woe_v1(transactions_train, transactions_test, col_get_prob, 'target_flag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Средние значения по MCC и каналу привлечения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00,  6.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "def mmode(x):\n",
    "    return mode(x)[0][0]\n",
    "\n",
    "for i in tqdm(['trx_category_woe', 'MCC_woe', 'channel_type_woe']):\n",
    "    temp = transactions_train[['cl_id',i]].groupby('cl_id').agg(mmode).reset_index()\n",
    "    \n",
    "    temp = pd.DataFrame(temp.values)\n",
    "    new_cols = ['cl_id',i]\n",
    "\n",
    "    temp.columns = new_cols\n",
    "    df = temp\n",
    "    df_train = pd.merge(df_train, temp, how='left', on='cl_id')\n",
    "    \n",
    "for i in tqdm(['trx_category_woe', 'MCC_woe', 'channel_type_woe']):\n",
    "    temp = transactions_test[['cl_id',i]].groupby('cl_id').agg(mmode).reset_index()\n",
    "    \n",
    "    temp = pd.DataFrame(temp.values)\n",
    "    new_cols = ['cl_id',i]\n",
    "\n",
    "    temp.columns = new_cols\n",
    "    df = temp\n",
    "    df_test = pd.merge(df_test, temp, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_deals = transactions_train[['cl_id','amount']].groupby('cl_id').agg('count').reset_index()\n",
    "num_deals.columns = ['cl_id','num_deals']\n",
    "df_train = pd.merge(df_train, num_deals, how='left', on='cl_id')\n",
    "\n",
    "sum_deals = transactions_train[['cl_id','amount']].groupby('cl_id').agg('sum').reset_index()\n",
    "sum_deals.columns = ['cl_id','sum_deals']\n",
    "df_train = pd.merge(df_train, sum_deals, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_deals = transactions_test[['cl_id','amount']].groupby('cl_id').agg('count').reset_index()\n",
    "num_deals.columns = ['cl_id','num_deals']\n",
    "df_test = pd.merge(df_test, num_deals, how='left', on='cl_id')\n",
    "\n",
    "sum_deals = transactions_test[['cl_id','amount']].groupby('cl_id').agg('sum').reset_index()\n",
    "sum_deals.columns = ['cl_id','sum_deals']\n",
    "df_test = pd.merge(df_test, sum_deals, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = transactions_test[['cl_id','target_flag']].groupby('cl_id').agg('mean').reset_index()\n",
    "test_y.columns = ['cl_id','target_flag']\n",
    "df_test = pd.merge(df_test, test_y, how='left', on='cl_id')\n",
    "\n",
    "train_y = transactions_train[['cl_id','target_flag']].groupby('cl_id').agg('mean').reset_index()\n",
    "train_y.columns = ['cl_id','target_flag']\n",
    "df_train = pd.merge(df_train, train_y, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разложение категорий транзакций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 74.34it/s]\n",
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 41.92it/s]\n"
     ]
    }
   ],
   "source": [
    "to_agg = ['sum','mean','std','median','max','min','count']\n",
    "for j in tqdm(pd.unique(transactions_test['trx_category'])):\n",
    "    i = 'amount'\n",
    "    temp = transactions_test[transactions_test['trx_category']==j][['cl_id',i]].groupby('cl_id').agg(to_agg).reset_index().fillna(0)\n",
    "    new_cols = ['cl_id']\n",
    "    for p in range(1,temp.columns.shape[0]):\n",
    "        new_cols.append('trx_category'+'_'+str(j)+'_'+i+'_'+str(to_agg[p-1]))\n",
    "    temp.columns = new_cols\n",
    "    df_test = pd.merge(df_test, temp, how='left', on='cl_id')\n",
    "    \n",
    "for j in tqdm(pd.unique(transactions_train['trx_category'])):\n",
    "    i = 'amount'\n",
    "    temp = transactions_train[transactions_train['trx_category']==j][['cl_id',i]].groupby('cl_id').agg(to_agg).reset_index().fillna(0)\n",
    "    new_cols = ['cl_id']\n",
    "    for p in range(1,temp.columns.shape[0]):\n",
    "        new_cols.append('trx_category'+'_'+str(j)+'_'+i+'_'+str(to_agg[p-1]))\n",
    "    temp.columns = new_cols\n",
    "    df_train = pd.merge(df_train, temp, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с датами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)### Работа с датами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = transactions_train[['cl_id','month']].groupby('cl_id').mean().reset_index()\n",
    "month.columns = ['cl_id','month']\n",
    "df_train = pd.merge(df_train, month, how='left', on='cl_id')\n",
    "\n",
    "month = transactions_test[['cl_id','month']].groupby('cl_id').mean().reset_index()\n",
    "month.columns = ['cl_id','month']\n",
    "df_test = pd.merge(df_test, month, how='left', on='cl_id')\n",
    "\n",
    "days_since2015 = transactions_train[['cl_id','days_since2015']].groupby('cl_id').mean().reset_index()\n",
    "days_since2015.columns = ['cl_id','days_since2015']\n",
    "df_train = pd.merge(df_train, days_since2015, how='left', on='cl_id')\n",
    "\n",
    "days_since2015 = transactions_test[['cl_id','days_since2015']].groupby('cl_id').mean().reset_index()\n",
    "days_since2015.columns = ['cl_id','days_since2015']\n",
    "df_test = pd.merge(df_test, days_since2015, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа над разложением MCC кодов на фичи и их разложение на главные компоненты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 325/325 [00:12<00:00, 25.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm(pd.unique(transactions_train['MCC'])):\n",
    "    i = 'amount'\n",
    "    temp = transactions_train[transactions_train['MCC']==j][['cl_id',i]].groupby('cl_id').agg('sum').reset_index().fillna(0)\n",
    "    new_cols = ['cl_id']\n",
    "    for p in range(1,temp.columns.shape[0]):\n",
    "        new_cols.append('MCC'+'_'+str(j)+'_'+i+'_'+str(to_agg[p-1]))\n",
    "    temp.columns = new_cols\n",
    "    df_train = pd.merge(df_train, temp, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 270/270 [00:07<00:00, 34.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm(pd.unique(transactions_test['MCC'])):\n",
    "    i = 'amount'\n",
    "    temp = transactions_test[transactions_test['MCC']==j][['cl_id',i]].groupby('cl_id').agg('sum').reset_index().fillna(0)\n",
    "    new_cols = ['cl_id']\n",
    "    for p in range(1,temp.columns.shape[0]):\n",
    "        new_cols.append('MCC'+'_'+str(j)+'_'+i+'_'+str(to_agg[p-1]))\n",
    "    temp.columns = new_cols\n",
    "    df_test = pd.merge(df_test, temp, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.columns & df_test.columns]\n",
    "df_test = df_train[df_train.columns & df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_flag                    1.000000\n",
       "channel_type_woe               0.377419\n",
       "num_days_in_use                0.275476\n",
       "num_deals                      0.244332\n",
       "trx_category_6_amount_count    0.230732\n",
       "                                 ...   \n",
       "MCC_4511_amount_sum           -0.101536\n",
       "trx_category_9_amount_min     -0.111150\n",
       "trx_category_5_amount_count   -0.112827\n",
       "MCC_5814_amount_sum           -0.179964\n",
       "cl_id                         -0.398544\n",
       "Name: target_flag, Length: 331, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df_train.corr()\n",
    "corr = corr_matrix[\"target_flag\"].sort_values(ascending=False)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y,y_pred):\n",
    "    print('accuracy_score =', accuracy_score(y,y_pred))\n",
    "    print('precision_score =', precision_score(y,y_pred,average='weighted'))\n",
    "    print('recall_score =', recall_score(y,y_pred,average='weighted'))\n",
    "    print('f1_score =', f1_score(y,y_pred,average='weighted'))\n",
    "    print('r2_score =', r2_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling (не помогло)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "df_train_scale = scale.fit_transform(df_train.drop(['target_flag'],axis=1))\n",
    "df_test_scale = scale.fit_transform(df_test.drop(['target_flag'],axis=1))\n",
    "X_train = df_train_scale.drop(['target_flag'],axis=1)\n",
    "X_test = df_train_scale.drop(['target_flag'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA  (исключается , если использовать начальные фичи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(df_train.fillna(0).drop(['cl_id'], axis=1))##### PCA  (исключается , если использовать начальные фичи)\n",
    "df_train_MCC_PCA = df_train.copy()\n",
    "df_test_MCC_PCA = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9, 1.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cum_evr = np.cumsum(pca.explained_variance_ratio_)\n",
    "xs = np.arange(cum_evr.size) + 1\n",
    "plt.plot(xs, cum_evr, linewidth=2)\n",
    "plt.grid()\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_ratio_')\n",
    "plt.xlim([0, 20])\n",
    "plt.ylim([0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15)\n",
    "\n",
    "principalComponents = pca.fit_transform(df_train_MCC_PCA.fillna(0).drop(['cl_id'], axis=1))\n",
    "df_train_MCC_PCA = pd.DataFrame(data = principalComponents , columns = ['p_c_1', 'p_c_2','p_c_3', 'p_c_4','p_c_5', 'p_c_6','p_c_7', 'p_c_8','p_c_9', 'p_c_10','p_c_11', 'p_c_12','p_c_13','p_c_14','p_c_15'])\n",
    "df_train_MCC_PCA['cl_id'] = df_train['cl_id']\n",
    "\n",
    "principalComponents = pca.fit_transform(df_test_MCC_PCA.fillna(0).drop(['cl_id'], axis=1))\n",
    "df_test_MCC_PCA = pd.DataFrame(data = principalComponents , columns = ['p_c_1', 'p_c_2','p_c_3', 'p_c_4','p_c_5', 'p_c_6','p_c_7', 'p_c_8','p_c_9', 'p_c_10','p_c_11', 'p_c_12','p_c_13','p_c_14','p_c_15'])\n",
    "df_test_MCC_PCA['cl_id'] = df_test['cl_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_train_MCC_PCA, how='left', on='cl_id') # For using main components\n",
    "df_test = pd.merge(df_test, df_test_MCC_PCA, how='left', on='cl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(max_iter=10000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['target_flag'],axis=1)\n",
    "y_train = df_train['target_flag']\n",
    "#X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Попробуй запусти на 2.5 часа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kf = KFold(len(y),n_splits=10,shuffle=False)\n",
    "y_pred = y.copy()\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train = y[train_index]\n",
    "        \n",
    "    log.fit(X_train,y_train)\n",
    "    \n",
    "    solver = ['liblinear']\n",
    "    penalty = ['l1', 'l2']\n",
    "    C = np.logspace(0, 4, 10)\n",
    "    hyperparameters = dict(C=C, penalty=penalty,solver=solver)\n",
    "        \n",
    "    clf = GridSearchCV(log, hyperparameters, cv=10, verbose=0)\n",
    "        \n",
    "    best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred[test_index] = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penalty = ['l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "        \n",
    "clf = GridSearchCV(log, hyperparameters, cv=10, verbose=0)\n",
    "        \n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred[test_index] = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(accuracy_score(y,y_pred))\n",
    "print(f1_score(y,y_pred,average='weighted'))\n",
    "print(precision_score(y,y_pred,average='weighted'))\n",
    "print(recall_score(y,y_pred,average='weighted'))\n",
    "print(r2_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['target_flag'],axis=1)\n",
    "y_train = df_train['target_flag']\n",
    "X_test = df_test.drop(['target_flag'],axis=1)\n",
    "y = df_test['target_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penalty = ['l2','elasticnet']\n",
    "C = np.logspace(0, 4, 10)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "log = LogisticRegression(max_iter=10000)\n",
    "\n",
    "clf = GridSearchCV(log, hyperparameters, cv=10, verbose=0)\n",
    "        \n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred[test_index] = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, n_jobs=-1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression( penalty='l1', solver='liblinear',max_iter=10000, n_jobs=4)\n",
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Lasso = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7655"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_test[['target_flag']], y_pred_Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05501086032294844"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(df_test[['target_flag']], y_pred_Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7385438558480483"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score = average_precision_score(df_test[['target_flag']], y_pred_Lasso)\n",
    "average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.7655\n",
      "precision_score = 0.7679885354141657\n",
      "recall_score = 0.7655\n",
      "f1_score = 0.7659112958299864\n",
      "r2_score = 0.05501086032294844\n"
     ]
    }
   ],
   "source": [
    "score(y,y_pred_Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df_train.drop(['target_flag'], axis=1), df_train['target_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CVM = clf.predict(df_test.drop(['target_flag'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.653\n",
      "precision_score = 0.6792346374911662\n",
      "recall_score = 0.653\n",
      "f1_score = 0.64899146639524\n",
      "r2_score = -0.39834213845602084\n"
     ]
    }
   ],
   "source": [
    "score(y,y_pred_CVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.001, gamma=5)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel_svm_clf = SVC(kernel=\"rbf\", gamma=5, C=0.001)\n",
    "rbf_kernel_svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rbf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.653\n",
      "precision_score = 0.6792346374911662\n",
      "recall_score = 0.653\n",
      "f1_score = 0.64899146639524\n",
      "r2_score = -0.39834213845602084\n"
     ]
    }
   ],
   "source": [
    "score(y,y_pred_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_kernel_svm = SVC(kernel=\"poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_kernel_svm.fit(df_train.drop(['target_flag'], axis=1), df_train['target_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_poly_kernel = poly_kernel_svm.predict(df_test.drop(['target_flag'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.55275\n",
      "precision_score = 0.6944867083191916\n",
      "recall_score = 0.55275\n",
      "f1_score = 0.40659609799928564\n",
      "r2_score = -0.8023300329235024\n"
     ]
    }
   ],
   "source": [
    "score(y,y_pred_poly_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import lightgbm as lgb\n",
    "skf = RepeatedStratifiedKFold(n_splits=8, n_repeats=5, random_state=201805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1939, number of negative: 1561\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1939, number of negative: 1561\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1939, number of negative: 1561\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1939, number of negative: 1561\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1940, number of negative: 1560\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] Number of positive: 1939, number of negative: 1561\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13141\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 78\n",
      "[LightGBM] [Warning] Unknown parameter: class_weight\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554000 -> initscore=0.216846\n",
      "[LightGBM] [Info] Start training from score 0.216846\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554000 -> initscore=0.216846\n",
      "[LightGBM] [Info] Start training from score 0.216846\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554000 -> initscore=0.216846\n",
      "[LightGBM] [Info] Start training from score 0.216846\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554000 -> initscore=0.216846\n",
      "[LightGBM] [Info] Start training from score 0.216846\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554286 -> initscore=0.218002\n",
      "[LightGBM] [Info] Start training from score 0.218002\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.554000 -> initscore=0.216846\n",
      "[LightGBM] [Info] Start training from score 0.216846\n",
      "[10]\tcv_agg's auc: 0.840522 + 0.0191282\n",
      "[20]\tcv_agg's auc: 0.839982 + 0.0191156\n",
      "[30]\tcv_agg's auc: 0.837662 + 0.0194837\n",
      "[40]\tcv_agg's auc: 0.840023 + 0.0195575\n",
      "[50]\tcv_agg's auc: 0.842657 + 0.0191666\n",
      "[60]\tcv_agg's auc: 0.842122 + 0.0191722\n",
      "[70]\tcv_agg's auc: 0.843338 + 0.0191807\n",
      "[80]\tcv_agg's auc: 0.843773 + 0.0192341\n",
      "[90]\tcv_agg's auc: 0.844821 + 0.0190571\n",
      "[100]\tcv_agg's auc: 0.846627 + 0.0188476\n",
      "[110]\tcv_agg's auc: 0.847203 + 0.0187799\n",
      "[120]\tcv_agg's auc: 0.848144 + 0.0187067\n",
      "[130]\tcv_agg's auc: 0.848796 + 0.018518\n",
      "[140]\tcv_agg's auc: 0.84916 + 0.0186137\n",
      "[150]\tcv_agg's auc: 0.849906 + 0.0185739\n",
      "[160]\tcv_agg's auc: 0.850469 + 0.0184842\n",
      "[170]\tcv_agg's auc: 0.85056 + 0.0186328\n",
      "[180]\tcv_agg's auc: 0.850425 + 0.0188457\n",
      "[190]\tcv_agg's auc: 0.850905 + 0.018788\n",
      "[200]\tcv_agg's auc: 0.851304 + 0.0187218\n",
      "[210]\tcv_agg's auc: 0.851712 + 0.0186718\n",
      "[220]\tcv_agg's auc: 0.851859 + 0.0186671\n",
      "[230]\tcv_agg's auc: 0.852346 + 0.0186912\n",
      "[240]\tcv_agg's auc: 0.852605 + 0.0187407\n",
      "[250]\tcv_agg's auc: 0.85302 + 0.0188171\n",
      "[260]\tcv_agg's auc: 0.853228 + 0.0187803\n",
      "[270]\tcv_agg's auc: 0.8533 + 0.0188341\n",
      "[280]\tcv_agg's auc: 0.853773 + 0.0187982\n",
      "[290]\tcv_agg's auc: 0.853903 + 0.0187306\n",
      "[300]\tcv_agg's auc: 0.854226 + 0.018711\n",
      "[310]\tcv_agg's auc: 0.85452 + 0.0187307\n",
      "[320]\tcv_agg's auc: 0.854968 + 0.0186612\n",
      "[330]\tcv_agg's auc: 0.85523 + 0.0186273\n",
      "[340]\tcv_agg's auc: 0.855344 + 0.0186867\n",
      "[350]\tcv_agg's auc: 0.855558 + 0.0186778\n",
      "[360]\tcv_agg's auc: 0.85574 + 0.0186543\n",
      "[370]\tcv_agg's auc: 0.856018 + 0.0186601\n",
      "[380]\tcv_agg's auc: 0.856043 + 0.0186879\n",
      "[390]\tcv_agg's auc: 0.856165 + 0.0186765\n",
      "[400]\tcv_agg's auc: 0.856308 + 0.0186762\n",
      "[410]\tcv_agg's auc: 0.856498 + 0.0186553\n",
      "[420]\tcv_agg's auc: 0.856527 + 0.0186946\n",
      "[430]\tcv_agg's auc: 0.856648 + 0.0187662\n",
      "[440]\tcv_agg's auc: 0.856746 + 0.0187981\n",
      "[450]\tcv_agg's auc: 0.856677 + 0.0188415\n",
      "[460]\tcv_agg's auc: 0.856792 + 0.0188691\n",
      "[470]\tcv_agg's auc: 0.856912 + 0.0188828\n",
      "[480]\tcv_agg's auc: 0.856929 + 0.0189372\n",
      "[490]\tcv_agg's auc: 0.856999 + 0.0189846\n",
      "[500]\tcv_agg's auc: 0.85699 + 0.0190445\n",
      "[510]\tcv_agg's auc: 0.856965 + 0.0190386\n",
      "[520]\tcv_agg's auc: 0.857113 + 0.0190317\n",
      "[530]\tcv_agg's auc: 0.857173 + 0.0190238\n",
      "[540]\tcv_agg's auc: 0.857142 + 0.0190645\n",
      "[550]\tcv_agg's auc: 0.857213 + 0.0190191\n",
      "[560]\tcv_agg's auc: 0.857195 + 0.0190015\n",
      "[570]\tcv_agg's auc: 0.857165 + 0.0189922\n",
      "[580]\tcv_agg's auc: 0.857088 + 0.0190728\n",
      "[590]\tcv_agg's auc: 0.857069 + 0.0191134\n"
     ]
    }
   ],
   "source": [
    "lgb_data_train = lgb.Dataset(df_train.drop(['target_flag'],axis=1), \n",
    "                             df_train['target_flag'], \n",
    "                             free_raw_data=False\n",
    "                            )\n",
    "\n",
    "params = {\n",
    "    'objective':'binary', \n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.01, \n",
    "    'random_state':4242442,\n",
    "    'subsample':0.33,\n",
    "    'class_weight':'balanced',\n",
    "    'colsample_bytree':0.33,\n",
    "    'reg_lambda':4\n",
    "}\n",
    "\n",
    "h = lgb.cv(params, \n",
    "           lgb_data_train, \n",
    "           num_boost_round=10000,\n",
    "           early_stopping_rounds=50, \n",
    "           verbose_eval=10, \n",
    "           folds=skf.split(df_train, df_train['target_flag'])\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа 2\n",
    "\n",
    "1. **Обязательная часть**: на том же наборе данных провести feature engineering:\n",
    "    - создать Weights of Evidence (WOE) фичи на тех переменных, где категорий большое количество\n",
    "    - cделать one hot encoding там, где необходимо\n",
    "    - по желанию посчитать каунты (counts)\n",
    "    \n",
    "2. **Обязательная часть**: обучить linear SVM и SVM с нелинейным ядром - сравнить время обучения и результат метрики оценки качества (ROC AUC) двух алгоритмов между собой и сравнить с линейной моделью (лог.рег)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
